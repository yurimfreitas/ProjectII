{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages gerais\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# df_sales_ dataset\n",
    "df_sales_filtered_2019 = joblib.load('df_sales_filtered_2019.pkl')\n",
    "#df_sales_filtered_all = joblib.load('df_sales_filtered_all.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Create a date field based in Year and Week of the year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 But the date to make sense should be the last day in that specific week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# Function to get the last day of the week using ISO calendar\n",
    "def get_last_day_of_iso_week(year, week):\n",
    "    first_day_of_year = datetime.datetime(year, 1, 4)  # 4th January is always in the first ISO week\n",
    "    first_monday_of_year = first_day_of_year - datetime.timedelta(days=first_day_of_year.weekday())\n",
    "    week_start_date = first_monday_of_year + datetime.timedelta(weeks=week-1)\n",
    "    return week_start_date + datetime.timedelta(days=6)\n",
    "\n",
    "# Applying function to DataFrame\n",
    "df_sales_filtered_2019['last_day_of_week'] = df_sales_filtered_2019.apply(\n",
    "    lambda x: get_last_day_of_iso_week(x['year'], x['week']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sales_filtered_2019 = df_sales_filtered_2019[(df_sales_filtered_2019['store_id'] == 'S0097') & (df_sales_filtered_2019['product_id'].isin(['P0001', 'P0704', 'P0702','P0747']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Convert date to time series by set as index and sort that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'date' column as index and sort by date\n",
    "df_sales_filtered_2019.set_index('last_day_of_week', inplace=True)\n",
    "df_sales_filtered_2019.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sales_filtered_2019.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Prepare to apply ARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'store_id' and 'product_id'\n",
    "grouped = df_sales_filtered_2019.groupby(['store_id', 'product_id'])\n",
    "\n",
    "# Create a DataFrame to store forecasts and a data frame to have those product/store with error\n",
    "df_forecasts = pd.DataFrame(columns=['store_id', 'product_id', 'forecast_week_1', 'forecast_week_2', 'forecast_week_3', 'ARIMAX'])\n",
    "df_product_error = pd.DataFrame(columns=['store_id', 'product_id', 'error_message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Function to perform grid search for ARIMAX parameters\n",
    "def optimize_arimax(series, exog, p_values, d_value, q_values):\n",
    "    best_aic = float(\"inf\")\n",
    "    best_order = None\n",
    "    best_model = None\n",
    "    for p, q in product(p_values, q_values):\n",
    "        try:\n",
    "            model = SARIMAX(series, exog=exog, order=(p, d_value, q))\n",
    "            model_fit = model.fit(disp=False)\n",
    "            aic = model_fit.aic\n",
    "            if aic < best_aic:\n",
    "                best_aic = aic\n",
    "                best_order = (p, d_value, q)\n",
    "                best_model = model_fit\n",
    "        except:\n",
    "            continue\n",
    "    return best_order, best_model\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(actual, forecast):\n",
    "    mse = mean_squared_error(actual, forecast)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, forecast)\n",
    "    mape = np.mean(np.abs((actual - forecast) / actual)) * 100\n",
    "    return mse, rmse, mae, mape\n",
    "\n",
    "# DataFrames to store results\n",
    "df_forecasts = pd.DataFrame(columns=['store_id', 'product_id', 'forecast_week_1', 'forecast_week_2', 'forecast_week_3', 'ARIMAX'])\n",
    "df_product_error = pd.DataFrame(columns=['store_id', 'product_id', 'error_message'])\n",
    "df_metrics = pd.DataFrame(columns=['store_id', 'product_id', 'mse', 'rmse', 'mae', 'mape'])\n",
    "\n",
    "# Grid search parameters\n",
    "p_values = range(0, 3)\n",
    "d_value  = 1\n",
    "q_values = range(0, 3)\n",
    "\n",
    "# Iterate over each group\n",
    "for (store_id, product_id), group in grouped:\n",
    "    # Reindex to ensure complete weekly intervals\n",
    "    group = group.asfreq('W-SUN', method='pad')\n",
    "    \n",
    "    # Ensure there are enough data points to fit the model\n",
    "    if len(group) < 6:  # Need at least 6 data points to train and test\n",
    "        df_product_error = pd.concat([df_product_error, pd.DataFrame([{\n",
    "            'store_id': store_id,\n",
    "            'product_id': product_id,\n",
    "            'error_message': 'Not enough data points to fit ARIMAX model'\n",
    "        }])], ignore_index=True)\n",
    "        continue\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")  # specify to ignore warning messages\n",
    "\n",
    "    # Fit ARIMAX model\n",
    "    try:\n",
    "        exog = group['price']\n",
    "        best_order, best_model = optimize_arimax(group['sales'], exog, p_values, d_value, q_values)\n",
    "       \n",
    "        if best_model is not None:\n",
    "            # Forecast future sales (next 3 weeks)\n",
    "            # Use the last 3 weeks of exog values for forecasting\n",
    "            forecast = best_model.forecast(steps=3, exog=exog[-3:])\n",
    "            actual = group['sales'][-3:].values  # Last 3 actual sales values\n",
    "            \n",
    "            # Calculate metrics\n",
    "            mse, rmse, mae, mape = calculate_metrics(actual, forecast)\n",
    "            \n",
    "            # Append the forecast and metrics to the DataFrames\n",
    "            df_forecasts = pd.concat([df_forecasts, pd.DataFrame([{\n",
    "                'store_id': store_id,\n",
    "                'product_id': product_id,\n",
    "                'forecast_week_1': forecast[0],\n",
    "                'forecast_week_2': forecast[1],\n",
    "                'forecast_week_3': forecast[2],\n",
    "                'ARIMAX': best_order\n",
    "            }])], ignore_index=True)\n",
    "            \n",
    "            df_metrics = pd.concat([df_metrics, pd.DataFrame([{\n",
    "                'store_id': store_id,\n",
    "                'product_id': product_id,\n",
    "                'mse': mse,\n",
    "                'rmse': rmse,\n",
    "                'mae': mae,\n",
    "                'mape': mape\n",
    "            }])], ignore_index=True)\n",
    "        else:\n",
    "            df_product_error = pd.concat([df_product_error, pd.DataFrame([{\n",
    "                'store_id': store_id,\n",
    "                'product_id': product_id,\n",
    "                'error_message': 'Failed to find suitable ARIMAX model'\n",
    "            }])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting ARIMAX for Store: {store_id}, Product: {product_id}\")\n",
    "        print(str(e))\n",
    "        df_product_error = pd.concat([df_product_error, pd.DataFrame([{\n",
    "            'store_id': store_id,\n",
    "            'product_id': product_id,\n",
    "            'error_message': str(e)\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "# Save the DataFrames to CSV files\n",
    "df_product_error.to_csv('product_errors_arimax.csv', index=False)\n",
    "df_metrics.to_csv('metrics_results_arimax.csv', index=False)\n",
    "df_forecasts.to_csv('forecasts_arimax.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>forecast_week_1</th>\n",
       "      <th>forecast_week_2</th>\n",
       "      <th>forecast_week_3</th>\n",
       "      <th>ARIMAX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2.902115</td>\n",
       "      <td>2.902115</td>\n",
       "      <td>2.902115</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0005</td>\n",
       "      <td>0.128170</td>\n",
       "      <td>0.128170</td>\n",
       "      <td>0.128170</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>(0, 1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0008</td>\n",
       "      <td>0.208437</td>\n",
       "      <td>0.208437</td>\n",
       "      <td>0.208437</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0009</td>\n",
       "      <td>1.717164</td>\n",
       "      <td>1.717164</td>\n",
       "      <td>1.717164</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0739</td>\n",
       "      <td>4.388750</td>\n",
       "      <td>4.388750</td>\n",
       "      <td>4.388750</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0740</td>\n",
       "      <td>0.481361</td>\n",
       "      <td>0.481361</td>\n",
       "      <td>0.481361</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0741</td>\n",
       "      <td>0.550506</td>\n",
       "      <td>0.550506</td>\n",
       "      <td>0.550506</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0747</td>\n",
       "      <td>29.511405</td>\n",
       "      <td>29.511405</td>\n",
       "      <td>29.511405</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1565 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     store_id product_id  forecast_week_1  forecast_week_2  forecast_week_3  \\\n",
       "0       S0020      P0001         2.902115         2.902115         2.902115   \n",
       "1       S0020      P0005         0.128170         0.128170         0.128170   \n",
       "2       S0020      P0007         0.000000         0.000000         0.000000   \n",
       "3       S0020      P0008         0.208437         0.208437         0.208437   \n",
       "4       S0020      P0009         1.717164         1.717164         1.717164   \n",
       "...       ...        ...              ...              ...              ...   \n",
       "1560    S0097      P0739         4.388750         4.388750         4.388750   \n",
       "1561    S0097      P0740         0.481361         0.481361         0.481361   \n",
       "1562    S0097      P0741         0.550506         0.550506         0.550506   \n",
       "1563    S0097      P0747        29.511405        29.511405        29.511405   \n",
       "1564    S0097      P0748         0.999997         0.999997         0.999997   \n",
       "\n",
       "         ARIMAX  \n",
       "0     (0, 1, 1)  \n",
       "1     (0, 1, 1)  \n",
       "2     (0, 1, 0)  \n",
       "3     (0, 1, 1)  \n",
       "4     (0, 1, 1)  \n",
       "...         ...  \n",
       "1560  (0, 1, 1)  \n",
       "1561  (0, 1, 1)  \n",
       "1562  (0, 1, 1)  \n",
       "1563  (0, 1, 1)  \n",
       "1564  (0, 1, 1)  \n",
       "\n",
       "[1565 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>sales</th>\n",
       "      <th>stock</th>\n",
       "      <th>last_day_of_week</th>\n",
       "      <th>ARIMAX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4727</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50267</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>38</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52905</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>39</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54470</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>40</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-10-06</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56035</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>41</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-10-13</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57600</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>42</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-10-20</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57601 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      store_id product_id  year  week     sales  stock last_day_of_week  \\\n",
       "0        S0020      P0001  2019     1  1.000000    7.0       2019-01-06   \n",
       "2196     S0020      P0001  2019     2  2.000000    5.0       2019-01-13   \n",
       "3115     S0020      P0001  2019     3  3.000000    2.0       2019-01-20   \n",
       "3603     S0020      P0001  2019     4  1.000000   11.0       2019-01-27   \n",
       "4727     S0020      P0001  2019     5  0.000000   11.0       2019-02-03   \n",
       "...        ...        ...   ...   ...       ...    ...              ...   \n",
       "50267    S0097      P0748  2019    38  1.000000    9.0       2019-09-22   \n",
       "52905    S0097      P0748  2019    39  1.000000    8.0       2019-09-29   \n",
       "54470    S0097      P0748  2019    40  0.999997    0.0       2019-10-06   \n",
       "56035    S0097      P0748  2019    41  0.999997    0.0       2019-10-13   \n",
       "57600    S0097      P0748  2019    42  0.999997    0.0       2019-10-20   \n",
       "\n",
       "          ARIMAX  \n",
       "0            NaN  \n",
       "2196         NaN  \n",
       "3115         NaN  \n",
       "3603         NaN  \n",
       "4727         NaN  \n",
       "...          ...  \n",
       "50267        NaN  \n",
       "52905        NaN  \n",
       "54470  (0, 1, 1)  \n",
       "56035  (0, 1, 1)  \n",
       "57600  (0, 1, 1)  \n",
       "\n",
       "[57601 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df_forecasts and df_sales_filtered_2019 are already defined\n",
    "\n",
    "# Pivot the forecasts DataFrame\n",
    "df_forecasts_melted = df_forecasts.melt(id_vars=['store_id', 'product_id', 'ARIMAX'], \n",
    "                                        value_vars=['forecast_week_1', 'forecast_week_2', 'forecast_week_3'], \n",
    "                                        var_name='week', value_name='forecast')\n",
    "\n",
    "# Extract the week number from the 'week' column\n",
    "df_forecasts_melted['week'] = df_forecasts_melted['week'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# Resetting index to ensure last_day_of_week is a regular column\n",
    "df_sales_filtered_2019.reset_index(drop=False, inplace=True)\n",
    "\n",
    "# Step 1: Find the latest year and week number for each store_id and product_id\n",
    "latest_weeks = df_sales_filtered_2019.groupby(['store_id', 'product_id'])[['year', 'week']].max().reset_index()\n",
    "latest_weeks.columns = ['store_id', 'product_id', 'latest_year', 'latest_week']\n",
    "\n",
    "# Step 2: Merge the latest year and week numbers with the forecast DataFrame\n",
    "df_combined = df_forecasts_melted.merge(latest_weeks, on=['store_id', 'product_id'], how='left')\n",
    "\n",
    "# Step 3: Add the forecast weeks to the latest week numbers, adjusting for year transition\n",
    "def adjust_year_week(row):\n",
    "    new_week = row['latest_week'] + row['week']\n",
    "    new_year = row['latest_year']\n",
    "    while new_week > 52:  # Assuming 52 weeks in a year\n",
    "        new_week -= 52\n",
    "        new_year += 1\n",
    "    return new_year, new_week\n",
    "\n",
    "df_combined[['forecast_year', 'forecast_week']] = df_combined.apply(\n",
    "    lambda row: adjust_year_week(row), axis=1, result_type=\"expand\"\n",
    ")\n",
    "\n",
    "# Step 4: Calculate the forecast's last_day_of_week based on forecast_year and forecast_week\n",
    "def get_last_day_of_iso_week(year, week):\n",
    "    first_day_of_year = pd.Timestamp(year, 1, 4)\n",
    "    first_monday_of_year = first_day_of_year - pd.Timedelta(days=first_day_of_year.weekday())\n",
    "    week_start_date = first_monday_of_year + pd.Timedelta(weeks=week-1)\n",
    "    return week_start_date + pd.Timedelta(days=6)\n",
    "\n",
    "df_combined['last_day_of_week'] = df_combined.apply(\n",
    "    lambda row: get_last_day_of_iso_week(row['forecast_year'], row['forecast_week']), axis=1\n",
    ")\n",
    "\n",
    "# Step 5: Select and rename the necessary columns to match the desired format, using forecast as sales\n",
    "df_combined_final = df_combined[['store_id', 'product_id', 'forecast_year', 'forecast_week', 'forecast', 'last_day_of_week', 'ARIMAX']]\n",
    "df_combined_final.columns = ['store_id', 'product_id', 'year', 'week', 'sales', 'last_day_of_week', 'ARIMAX']\n",
    "\n",
    "# Include 'stock' column in the final combined data with 0 for forecasted sales\n",
    "df_combined_final['stock'] = 0\n",
    "\n",
    "# Step 6: Concatenate with the original sales DataFrame\n",
    "df_sales_final_arimax = df_sales_filtered_2019[['store_id', 'product_id', 'year', 'week', 'sales', 'stock', 'last_day_of_week']]\n",
    "df_sales_final_arimax ['ARIMAX'] = np.nan  # Adding ARIMAX column with NaN for actual sales\n",
    "\n",
    "df_final_arimax = pd.concat([df_sales_final_arimax , df_combined_final[['store_id', 'product_id', 'year', 'week', 'sales', 'stock', 'last_day_of_week', 'ARIMAX']]], ignore_index=True).sort_values(by=['store_id', 'product_id', 'year', 'week'])\n",
    "\n",
    "# Display the final DataFrame\n",
    "df_final_arimax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>error_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0012</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0117</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0270</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0314</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0326</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0570</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0595</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0634</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0675</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0676</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_id product_id                               error_message\n",
       "0     S0020      P0012  Not enough data points to fit ARIMAX model\n",
       "1     S0020      P0117  Not enough data points to fit ARIMAX model\n",
       "2     S0020      P0270  Not enough data points to fit ARIMAX model\n",
       "3     S0020      P0314  Not enough data points to fit ARIMAX model\n",
       "4     S0020      P0326  Not enough data points to fit ARIMAX model\n",
       "..      ...        ...                                         ...\n",
       "62    S0097      P0570  Not enough data points to fit ARIMAX model\n",
       "63    S0097      P0595  Not enough data points to fit ARIMAX model\n",
       "64    S0097      P0634  Not enough data points to fit ARIMAX model\n",
       "65    S0097      P0675  Not enough data points to fit ARIMAX model\n",
       "66    S0097      P0676  Not enough data points to fit ARIMAX model\n",
       "\n",
       "[67 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the forecast DataFrame and the error DataFrame to CSV files\n",
    "df_final_arimax.to_csv('./Files/df_final_arimax.csv', index=False)\n",
    "df_product_error.to_csv('./Files/2019_forecast_errors_arimax.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>sales</th>\n",
       "      <th>stock</th>\n",
       "      <th>last_day_of_week</th>\n",
       "      <th>ARIMAX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4727</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50267</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>38</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52905</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>39</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54470</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>40</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-10-06</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56035</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>41</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-10-13</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57600</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>42</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-10-20</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57601 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      store_id product_id  year  week     sales  stock last_day_of_week  \\\n",
       "0        S0020      P0001  2019     1  1.000000    7.0       2019-01-06   \n",
       "2196     S0020      P0001  2019     2  2.000000    5.0       2019-01-13   \n",
       "3115     S0020      P0001  2019     3  3.000000    2.0       2019-01-20   \n",
       "3603     S0020      P0001  2019     4  1.000000   11.0       2019-01-27   \n",
       "4727     S0020      P0001  2019     5  0.000000   11.0       2019-02-03   \n",
       "...        ...        ...   ...   ...       ...    ...              ...   \n",
       "50267    S0097      P0748  2019    38  1.000000    9.0       2019-09-22   \n",
       "52905    S0097      P0748  2019    39  1.000000    8.0       2019-09-29   \n",
       "54470    S0097      P0748  2019    40  0.999997    0.0       2019-10-06   \n",
       "56035    S0097      P0748  2019    41  0.999997    0.0       2019-10-13   \n",
       "57600    S0097      P0748  2019    42  0.999997    0.0       2019-10-20   \n",
       "\n",
       "          ARIMAX  \n",
       "0            NaN  \n",
       "2196         NaN  \n",
       "3115         NaN  \n",
       "3603         NaN  \n",
       "4727         NaN  \n",
       "...          ...  \n",
       "50267        NaN  \n",
       "52905        NaN  \n",
       "54470  (0, 1, 1)  \n",
       "56035  (0, 1, 1)  \n",
       "57600  (0, 1, 1)  \n",
       "\n",
       "[57601 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_arimax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 57601 entries, 0 to 57600\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   store_id          57601 non-null  object        \n",
      " 1   product_id        57601 non-null  object        \n",
      " 2   year              57601 non-null  Int64         \n",
      " 3   week              57601 non-null  Int64         \n",
      " 4   sales             57601 non-null  float64       \n",
      " 5   stock             57601 non-null  float64       \n",
      " 6   last_day_of_week  57601 non-null  datetime64[ns]\n",
      " 7   ARIMAX            4695 non-null   object        \n",
      "dtypes: Int64(2), datetime64[ns](1), float64(2), object(3)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_final_arimax.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
