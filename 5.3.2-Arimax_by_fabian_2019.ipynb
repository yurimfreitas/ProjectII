{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages gerais\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# df_sales_ dataset\n",
    "#df_sales_filtered_2019 = joblib.load('df_sales_filtered_2019.pkl')\n",
    "df_sales_filtered_all = joblib.load('df_sales_filtered_all.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Create a date field based in Year and Week of the year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 But the date to make sense should be the last day in that specific week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# Function to get the last day of the week using ISO calendar\n",
    "def get_last_day_of_iso_week(year, week):\n",
    "    first_day_of_year = datetime.datetime(year, 1, 4)  # 4th January is always in the first ISO week\n",
    "    first_monday_of_year = first_day_of_year - datetime.timedelta(days=first_day_of_year.weekday())\n",
    "    week_start_date = first_monday_of_year + datetime.timedelta(weeks=week-1)\n",
    "    return week_start_date + datetime.timedelta(days=6)\n",
    "\n",
    "# Applying function to DataFrame\n",
    "df_sales_filtered_all['last_day_of_week'] = df_sales_filtered_all.apply(\n",
    "    lambda x: get_last_day_of_iso_week(x['year'], x['week']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sales_filtered_2019 = df_sales_filtered_2019[(df_sales_filtered_2019['store_id'] == 'S0097') & (df_sales_filtered_2019['product_id'].isin(['P0001', 'P0704', 'P0702','P0747']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Convert date to time series by set as index and sort that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'date' column as index and sort by date\n",
    "df_sales_filtered_all.set_index('last_day_of_week', inplace=True)\n",
    "df_sales_filtered_all.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sales_filtered_2019.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Prepare to apply ARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'store_id' and 'product_id'\n",
    "grouped = df_sales_filtered_all.groupby(['store_id', 'product_id'])\n",
    "\n",
    "# Create a DataFrame to store forecasts and a data frame to have those product/store with error\n",
    "df_forecasts = pd.DataFrame(columns=['store_id', 'product_id', 'forecast_week_1', 'forecast_week_2', 'forecast_week_3', 'ARIMAX'])\n",
    "df_product_error = pd.DataFrame(columns=['store_id', 'product_id', 'error_message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Function to perform grid search for ARIMAX parameters\n",
    "def optimize_arimax(series, exog, p_values, d_value, q_values):\n",
    "    best_aic = float(\"inf\")\n",
    "    best_order = None\n",
    "    best_model = None\n",
    "    for p, q in product(p_values, q_values):\n",
    "        try:\n",
    "            model = SARIMAX(series, exog=exog, order=(p, d_value, q))\n",
    "            model_fit = model.fit(disp=False)\n",
    "            aic = model_fit.aic\n",
    "            if aic < best_aic:\n",
    "                best_aic = aic\n",
    "                best_order = (p, d_value, q)\n",
    "                best_model = model_fit\n",
    "        except:\n",
    "            continue\n",
    "    return best_order, best_model\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(actual, forecast):\n",
    "    mse = mean_squared_error(actual, forecast)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, forecast)\n",
    "    mape = np.mean(np.abs((actual - forecast) / actual)) * 100\n",
    "    return mse, rmse, mae, mape\n",
    "\n",
    "# DataFrames to store results\n",
    "df_forecasts = pd.DataFrame(columns=['store_id', 'product_id', 'forecast_week_1', 'forecast_week_2', 'forecast_week_3', 'ARIMAX'])\n",
    "df_product_error = pd.DataFrame(columns=['store_id', 'product_id', 'error_message'])\n",
    "df_metrics = pd.DataFrame(columns=['store_id', 'product_id', 'mse', 'rmse', 'mae', 'mape'])\n",
    "\n",
    "# Grid search parameters\n",
    "p_values = range(0, 3)\n",
    "d_value  = 1\n",
    "q_values = range(0, 3)\n",
    "\n",
    "# Iterate over each group\n",
    "for (store_id, product_id), group in grouped:\n",
    "    # Reindex to ensure complete weekly intervals\n",
    "    group = group.asfreq('W-SUN', method='pad')\n",
    "    \n",
    "    # Ensure there are enough data points to fit the model\n",
    "    if len(group) < 6:  # Need at least 6 data points to train and test\n",
    "        df_product_error = pd.concat([df_product_error, pd.DataFrame([{\n",
    "            'store_id': store_id,\n",
    "            'product_id': product_id,\n",
    "            'error_message': 'Not enough data points to fit ARIMAX model'\n",
    "        }])], ignore_index=True)\n",
    "        continue\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")  # specify to ignore warning messages\n",
    "\n",
    "    # Fit ARIMAX model\n",
    "    try:\n",
    "        exog = group['price']\n",
    "        best_order, best_model = optimize_arimax(group['sales'], exog, p_values, d_value, q_values)\n",
    "       \n",
    "        if best_model is not None:\n",
    "            # Forecast future sales (next 3 weeks)\n",
    "            # Use the last 3 weeks of exog values for forecasting\n",
    "            forecast = best_model.forecast(steps=3, exog=exog[-3:])\n",
    "            actual = group['sales'][-3:].values  # Last 3 actual sales values\n",
    "            \n",
    "            # Calculate metrics\n",
    "            mse, rmse, mae, mape = calculate_metrics(actual, forecast)\n",
    "            \n",
    "            # Append the forecast and metrics to the DataFrames\n",
    "            df_forecasts = pd.concat([df_forecasts, pd.DataFrame([{\n",
    "                'store_id': store_id,\n",
    "                'product_id': product_id,\n",
    "                'forecast_week_1': forecast[0],\n",
    "                'forecast_week_2': forecast[1],\n",
    "                'forecast_week_3': forecast[2],\n",
    "                'ARIMAX': best_order\n",
    "            }])], ignore_index=True)\n",
    "            \n",
    "            df_metrics = pd.concat([df_metrics, pd.DataFrame([{\n",
    "                'store_id': store_id,\n",
    "                'product_id': product_id,\n",
    "                'mse': mse,\n",
    "                'rmse': rmse,\n",
    "                'mae': mae,\n",
    "                'mape': mape\n",
    "            }])], ignore_index=True)\n",
    "        else:\n",
    "            df_product_error = pd.concat([df_product_error, pd.DataFrame([{\n",
    "                'store_id': store_id,\n",
    "                'product_id': product_id,\n",
    "                'error_message': 'Failed to find suitable ARIMAX model'\n",
    "            }])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting ARIMAX for Store: {store_id}, Product: {product_id}\")\n",
    "        print(str(e))\n",
    "        df_product_error = pd.concat([df_product_error, pd.DataFrame([{\n",
    "            'store_id': store_id,\n",
    "            'product_id': product_id,\n",
    "            'error_message': str(e)\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "# Save the DataFrames to CSV files\n",
    "df_product_error.to_csv('product_errors_arimax.csv', index=False)\n",
    "df_metrics.to_csv('metrics_results_arimax.csv', index=False)\n",
    "df_forecasts.to_csv('forecasts_arimax.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>forecast_week_1</th>\n",
       "      <th>forecast_week_2</th>\n",
       "      <th>forecast_week_3</th>\n",
       "      <th>ARIMAX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2.543150</td>\n",
       "      <td>2.543150</td>\n",
       "      <td>2.543150</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0005</td>\n",
       "      <td>0.139137</td>\n",
       "      <td>0.139137</td>\n",
       "      <td>0.139137</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>(0, 1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0008</td>\n",
       "      <td>0.300674</td>\n",
       "      <td>0.300674</td>\n",
       "      <td>0.300674</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0009</td>\n",
       "      <td>1.717164</td>\n",
       "      <td>1.717164</td>\n",
       "      <td>1.717164</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0739</td>\n",
       "      <td>5.274460</td>\n",
       "      <td>3.208062</td>\n",
       "      <td>3.007870</td>\n",
       "      <td>(2, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0740</td>\n",
       "      <td>0.869525</td>\n",
       "      <td>0.639088</td>\n",
       "      <td>0.592115</td>\n",
       "      <td>(1, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0741</td>\n",
       "      <td>0.483696</td>\n",
       "      <td>0.483696</td>\n",
       "      <td>0.483696</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0747</td>\n",
       "      <td>10.401855</td>\n",
       "      <td>10.401855</td>\n",
       "      <td>10.401855</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1573 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     store_id product_id  forecast_week_1  forecast_week_2  forecast_week_3  \\\n",
       "0       S0020      P0001         2.543150         2.543150         2.543150   \n",
       "1       S0020      P0005         0.139137         0.139137         0.139137   \n",
       "2       S0020      P0007         0.000000         0.000000         0.000000   \n",
       "3       S0020      P0008         0.300674         0.300674         0.300674   \n",
       "4       S0020      P0009         1.717164         1.717164         1.717164   \n",
       "...       ...        ...              ...              ...              ...   \n",
       "1568    S0097      P0739         5.274460         3.208062         3.007870   \n",
       "1569    S0097      P0740         0.869525         0.639088         0.592115   \n",
       "1570    S0097      P0741         0.483696         0.483696         0.483696   \n",
       "1571    S0097      P0747        10.401855        10.401855        10.401855   \n",
       "1572    S0097      P0748         0.999997         0.999997         0.999997   \n",
       "\n",
       "         ARIMAX  \n",
       "0     (0, 1, 1)  \n",
       "1     (0, 1, 1)  \n",
       "2     (0, 1, 0)  \n",
       "3     (0, 1, 1)  \n",
       "4     (0, 1, 1)  \n",
       "...         ...  \n",
       "1568  (2, 1, 1)  \n",
       "1569  (1, 1, 1)  \n",
       "1570  (0, 1, 1)  \n",
       "1571  (0, 1, 1)  \n",
       "1572  (0, 1, 1)  \n",
       "\n",
       "[1573 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>sales</th>\n",
       "      <th>last_day_of_week</th>\n",
       "      <th>ARIMAX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36246</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2017</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-11-12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36466</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2017</td>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-11-19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37690</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2017</td>\n",
       "      <td>47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-11-26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38446</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2017</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39771</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2017</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147058</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148795</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150368</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-10-06</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151941</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-10-13</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153514</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-10-20</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153515 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       store_id product_id  year  week  sales last_day_of_week     ARIMAX\n",
       "36246     S0020      P0001  2017    45    0.0       2017-11-12        NaN\n",
       "36466     S0020      P0001  2017    46    1.0       2017-11-19        NaN\n",
       "37690     S0020      P0001  2017    47    2.0       2017-11-26        NaN\n",
       "38446     S0020      P0001  2017    48    0.0       2017-12-03        NaN\n",
       "39771     S0020      P0001  2017    49    1.0       2017-12-10        NaN\n",
       "...         ...        ...   ...   ...    ...              ...        ...\n",
       "147058    S0097      P0748  2019    38    1.0       2019-09-22        NaN\n",
       "148795    S0097      P0748  2019    39    1.0       2019-09-29        NaN\n",
       "150368    S0097      P0748  2019    40    1.0       2019-10-06  (0, 1, 1)\n",
       "151941    S0097      P0748  2019    41    1.0       2019-10-13  (0, 1, 1)\n",
       "153514    S0097      P0748  2019    42    1.0       2019-10-20  (0, 1, 1)\n",
       "\n",
       "[153515 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This input and merge the data predicted with the sales already done\n",
    "import numpy as np\n",
    "\n",
    "# Pivot the forecasts DataFrame\n",
    "df_forecasts_melted = df_forecasts.melt(id_vars=['store_id', 'product_id', 'ARIMAX'], \n",
    "                                        value_vars=['forecast_week_1', 'forecast_week_2', 'forecast_week_3'], \n",
    "                                        var_name='week', value_name='forecast')\n",
    "\n",
    "# Extract the week number from the 'week' column\n",
    "df_forecasts_melted['week'] = df_forecasts_melted['week'].str.extract('(\\d+)').astype(int)\n",
    "df_forecasts_melted\n",
    "\n",
    "# Resetting index to ensure last_day_of_week is a regular column\n",
    "df_sales_filtered_all.reset_index(drop=False, inplace=True)\n",
    "\n",
    "# Step 1: Find the latest year and week number for each store_id and product_id\n",
    "latest_weeks = df_sales_filtered_all.groupby(['store_id', 'product_id'])[['year', 'week']].max().reset_index()\n",
    "latest_weeks.columns = ['store_id', 'product_id', 'latest_year', 'latest_week']\n",
    "\n",
    "# Step 2: Merge the latest year and week numbers with the forecast DataFrame\n",
    "df_combined = df_forecasts_melted.merge(latest_weeks, on=['store_id', 'product_id'], how='left')\n",
    "\n",
    "# Step 3: Add the forecast weeks to the latest week numbers, adjusting for year transition\n",
    "def adjust_year_week(row):\n",
    "    new_week = row['latest_week'] + row['week']\n",
    "    new_year = row['latest_year']\n",
    "    while new_week > 52:  # Assuming 52 weeks in a year\n",
    "        new_week -= 52\n",
    "        new_year += 1\n",
    "    return new_year, new_week\n",
    "\n",
    "df_combined[['forecast_year', 'forecast_week']] = df_combined.apply(\n",
    "    lambda row: adjust_year_week(row), axis=1, result_type=\"expand\"\n",
    ")\n",
    "\n",
    "# Step 4: Calculate the forecast's last_day_of_week based on forecast_year and forecast_week\n",
    "def get_last_day_of_iso_week(year, week):\n",
    "    first_day_of_year = pd.Timestamp(year, 1, 4)\n",
    "    first_monday_of_year = first_day_of_year - pd.Timedelta(days=first_day_of_year.weekday())\n",
    "    week_start_date = first_monday_of_year + pd.Timedelta(weeks=week-1)\n",
    "    return week_start_date + pd.Timedelta(days=6)\n",
    "\n",
    "df_combined['last_day_of_week'] = df_combined.apply(\n",
    "    lambda row: get_last_day_of_iso_week(row['forecast_year'], row['forecast_week']), axis=1\n",
    ")\n",
    "\n",
    "# Step 5: Select and rename the necessary columns to match the desired format, using forecast as sales\n",
    "df_combined_final = df_combined[['store_id', 'product_id', 'forecast_year', 'forecast_week', 'forecast', 'last_day_of_week', 'ARIMAX']]\n",
    "df_combined_final.columns = ['store_id', 'product_id', 'year', 'week', 'sales', 'last_day_of_week', 'ARIMAX']\n",
    "\n",
    "# Step 6: Concatenate with the original sales DataFrame\n",
    "df_sales_final = df_sales_filtered_all[['store_id', 'product_id', 'year', 'week', 'sales', 'last_day_of_week']]\n",
    "df_sales_final['ARIMAX'] = np.nan  # Adding ARIMAX column with NaN for actual sales\n",
    "\n",
    "df_final = pd.concat([df_sales_final, df_combined_final], ignore_index=True).sort_values(by=['store_id', 'product_id', 'year', 'week'])\n",
    "\n",
    "df_final['sales'] = df_final['sales'].round(2)\n",
    "# Display the final DataFrame\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>error_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0012</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0117</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0270</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0314</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0326</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0570</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0595</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0634</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0675</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0676</td>\n",
       "      <td>Not enough data points to fit ARIMAX model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_id product_id                               error_message\n",
       "0     S0020      P0012  Not enough data points to fit ARIMAX model\n",
       "1     S0020      P0117  Not enough data points to fit ARIMAX model\n",
       "2     S0020      P0270  Not enough data points to fit ARIMAX model\n",
       "3     S0020      P0314  Not enough data points to fit ARIMAX model\n",
       "4     S0020      P0326  Not enough data points to fit ARIMAX model\n",
       "..      ...        ...                                         ...\n",
       "62    S0097      P0570  Not enough data points to fit ARIMAX model\n",
       "63    S0097      P0595  Not enough data points to fit ARIMAX model\n",
       "64    S0097      P0634  Not enough data points to fit ARIMAX model\n",
       "65    S0097      P0675  Not enough data points to fit ARIMAX model\n",
       "66    S0097      P0676  Not enough data points to fit ARIMAX model\n",
       "\n",
       "[67 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the forecast DataFrame and the error DataFrame to CSV files\n",
    "df_final.to_csv('./Files/df_final.csv', index=False)\n",
    "df_product_error.to_csv('./Files/2019_forecast_errors_arimax.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>sales</th>\n",
       "      <th>last_day_of_week</th>\n",
       "      <th>ARIMAX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36246</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2017</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-11-12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36466</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2017</td>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-11-19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37690</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2017</td>\n",
       "      <td>47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-11-26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38446</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2017</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39771</th>\n",
       "      <td>S0020</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2017</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147058</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148795</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150368</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-10-06</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151941</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-10-13</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153514</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0748</td>\n",
       "      <td>2019</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-10-20</td>\n",
       "      <td>(0, 1, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153515 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       store_id product_id  year  week  sales last_day_of_week     ARIMAX\n",
       "36246     S0020      P0001  2017    45    0.0       2017-11-12        NaN\n",
       "36466     S0020      P0001  2017    46    1.0       2017-11-19        NaN\n",
       "37690     S0020      P0001  2017    47    2.0       2017-11-26        NaN\n",
       "38446     S0020      P0001  2017    48    0.0       2017-12-03        NaN\n",
       "39771     S0020      P0001  2017    49    1.0       2017-12-10        NaN\n",
       "...         ...        ...   ...   ...    ...              ...        ...\n",
       "147058    S0097      P0748  2019    38    1.0       2019-09-22        NaN\n",
       "148795    S0097      P0748  2019    39    1.0       2019-09-29        NaN\n",
       "150368    S0097      P0748  2019    40    1.0       2019-10-06  (0, 1, 1)\n",
       "151941    S0097      P0748  2019    41    1.0       2019-10-13  (0, 1, 1)\n",
       "153514    S0097      P0748  2019    42    1.0       2019-10-20  (0, 1, 1)\n",
       "\n",
       "[153515 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 153515 entries, 36246 to 153514\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   store_id          153515 non-null  object        \n",
      " 1   product_id        153515 non-null  object        \n",
      " 2   year              153515 non-null  Int64         \n",
      " 3   week              153515 non-null  Int64         \n",
      " 4   sales             153515 non-null  float64       \n",
      " 5   last_day_of_week  153515 non-null  datetime64[ns]\n",
      " 6   ARIMAX            4719 non-null    object        \n",
      "dtypes: Int64(2), datetime64[ns](1), float64(1), object(3)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_final.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
