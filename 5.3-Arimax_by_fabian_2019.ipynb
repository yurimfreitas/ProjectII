{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages gerais\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "\n",
    "# df_sales_ dataset\n",
    "df_sales_filtered_2019 = joblib.load('df_sales_filtered_2019.pkl')\n",
    "df_sales_filtered = joblib.load('df_sales_filtered.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61507 entries, 0 to 61506\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   store_id    61507 non-null  object \n",
      " 1   product_id  61507 non-null  object \n",
      " 2   year        61507 non-null  UInt32 \n",
      " 3   week        61507 non-null  UInt32 \n",
      " 4   sales       61507 non-null  float64\n",
      " 5   revenue     61507 non-null  float64\n",
      " 6   stock       61507 non-null  float64\n",
      " 7   price       61507 non-null  float64\n",
      "dtypes: UInt32(2), float64(4), object(2)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "    df_sales_filtered_2019.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# Function to get the last day of the week using ISO calendar\n",
    "def get_last_day_of_iso_week(year, week):\n",
    "    first_day_of_year = datetime.datetime(year, 1, 4)  # 4th January is always in the first ISO week\n",
    "    first_monday_of_year = first_day_of_year - datetime.timedelta(days=first_day_of_year.weekday())\n",
    "    week_start_date = first_monday_of_year + datetime.timedelta(weeks=week-1)\n",
    "    return week_start_date + datetime.timedelta(days=6)\n",
    "\n",
    "# Applying function to DataFrame\n",
    "df_sales_filtered_2019['last_day_of_week'] = df_sales_filtered_2019.apply(\n",
    "    lambda x: get_last_day_of_iso_week(x['year'], x['week']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_filtered_2019[(df_sales_filtered_2019['store_id'] == 'S0097') & (df_sales_filtered_2019['product_id'] == 'P0704')].tail(30)\n",
    "\n",
    "df_1 = df_sales_filtered_2019[(df_sales_filtered_2019['store_id'] == 'S0097') & (df_sales_filtered_2019['product_id'].isin(['', 'P0001']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>sales</th>\n",
       "      <th>revenue</th>\n",
       "      <th>stock</th>\n",
       "      <th>price</th>\n",
       "      <th>last_day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49063</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2019</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.95</td>\n",
       "      <td>2019-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49064</th>\n",
       "      <td>S0097</td>\n",
       "      <td>P0001</td>\n",
       "      <td>2019</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.95</td>\n",
       "      <td>2019-08-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      store_id product_id  year  week  sales  revenue  stock  price  \\\n",
       "49063    S0097      P0001  2019    33    0.0     0.00    1.0  10.95   \n",
       "49064    S0097      P0001  2019    34    1.0     9.28    0.0  10.95   \n",
       "\n",
       "      last_day_of_week  \n",
       "49063       2019-08-18  \n",
       "49064       2019-08-25  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales_filtered_2019 = df_1\n",
    "\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'date' column as index and sort by date\n",
    "df_sales_filtered_2019.set_index('last_day_of_week', inplace=True)\n",
    "df_sales_filtered_2019.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'store_id' and 'product_id'\n",
    "grouped = df_sales_filtered_2019.groupby(['store_id', 'product_id'])\n",
    "\n",
    "# Create a DataFrame to store forecasts and a data frame to have those product/store with error\n",
    "df_forecasts = pd.DataFrame(columns=['store_id', 'product_id', 'forecast_week_1', 'forecast_week_2', 'forecast_week_3'])\n",
    "df_product_error = pd.DataFrame(columns=['store_id', 'product_id', 'error_message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antes do for\n",
      "depois do for\n",
      "depois do len\n",
      "S0097\n",
      "P0001\n",
      "Previsões ARIMAX:\n",
      "Empty DataFrame\n",
      "Columns: [store_id, product_id, forecast_week_1, forecast_week_2, forecast_week_3, ARIMAX]\n",
      "Index: []\n",
      "\n",
      "Erros de Produtos ARIMAX:\n",
      "  store_id product_id                               error_message\n",
      "0     S097       P001  Not enough data points to fit ARIMAX model\n",
      "\n",
      "Métricas ARIMAX:\n",
      "Empty DataFrame\n",
      "Columns: [store_id, product_id, mse, rmse, mae, mape]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "\n",
    "# Criar o DataFrame exog a partir das colunas 'price' e 'stock'\n",
    "df_exog = df_sales_filtered_2019[['price']]\n",
    "\n",
    "# Codificar 'price' se necessário (caso tenha valores categóricos)\n",
    "df_exog = pd.get_dummies(df_exog, columns=['price'], drop_first=True)\n",
    "\n",
    "# Agrupar por store_id e product_id\n",
    "grouped = df_sales_filtered_2019.groupby(['store_id', 'product_id'])\n",
    "\n",
    "# Função para realizar busca de parâmetros para ARIMAX\n",
    "def optimize_arimax(series, exog, p_values, d_value, q_values):\n",
    "    best_aic = float(\"inf\")\n",
    "    best_order = None\n",
    "    best_model = None\n",
    "    for p, q in product(p_values, q_values):\n",
    "        try:\n",
    "            model = SARIMAX(series, exog=exog, order=(p, d_value, q))\n",
    "            model_fit = model.fit(disp=False)\n",
    "            aic = model_fit.aic\n",
    "            if aic < best_aic:\n",
    "                best_aic = aic\n",
    "                best_order = (p, d_value, q)\n",
    "                best_model = model_fit\n",
    "        except ValueError as ve:\n",
    "            logging.error(f\"ValueError ao ajustar o modelo ARIMAX: {str(ve)}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Erro ao ajustar o modelo ARIMAX: {str(e)}\")\n",
    "            continue\n",
    "    return best_order, best_model\n",
    "\n",
    "# Função para calcular métricas\n",
    "def calculate_metrics(actual, predicted):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = mean_squared_error(actual, predicted, squared=False)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    mape = mean_absolute_percentage_error(actual, predicted)\n",
    "    return mse, rmse, mae, mape\n",
    "\n",
    "# Parâmetros para a busca de grid\n",
    "p_values = range(0, 3)\n",
    "d_value = 1\n",
    "q_values = range(0, 3)\n",
    "\n",
    "# DataFrames para armazenar resultados\n",
    "df_forecasts_arimax = pd.DataFrame(columns=['store_id', 'product_id', 'forecast_week_1', 'forecast_week_2', 'forecast_week_3', 'ARIMAX'])\n",
    "df_product_error_arimax = pd.DataFrame(columns=['store_id', 'product_id', 'error_message'])\n",
    "df_metrics_arimax = pd.DataFrame(columns=['store_id', 'product_id', 'mse', 'rmse', 'mae', 'mape'])\n",
    "print('antes do for')\n",
    "# Iterar sobre cada grupo\n",
    "for (store_id, product_id), group in grouped:\n",
    "    # Reindexar para garantir intervalos semanais completos\n",
    "    group = group.asfreq('W-SUN', method='pad')\n",
    "    print('depois do for')    \n",
    "    # Garantir que há pontos de dados suficientes para ajustar o modelo (mínimo 5 neste exemplo)\n",
    "    if len(group) < 3:\n",
    "        print('depois do len')\n",
    "        print(store_id)    \n",
    "        print(product_id)\n",
    "        \n",
    "        df_product_error_arimax = pd.concat([df_product_error_arimax, pd.DataFrame([{\n",
    "            'store_id': 'S097',\n",
    "            'product_id': 'P001',\n",
    "            'error_message': 'Not enough data points to fit ARIMAX model'\n",
    "        }])], ignore_index=False)\n",
    "        continue\n",
    "    print('antes do warning')\n",
    "    warnings.filterwarnings(\"ignore\")  # especificar para ignorar mensagens de aviso\n",
    "    print('antes do exog')\n",
    "    # Preparar variáveis exógenas (certificar-se de que 'df_exog' tenha o mesmo índice que 'group')\n",
    "    exog = df_exog.loc[group.index]\n",
    "    print('depois do exog')\n",
    "    # Ajustar o modelo ARIMAX\n",
    "    try:\n",
    "        best_order, best_model = optimize_arimax(group['sales'], exog, p_values, d_value, q_values)\n",
    "       \n",
    "        if best_model is not None:\n",
    "            # Prever vendas futuras (próximas 3 semanas)\n",
    "            forecast = best_model.get_forecast(steps=3, exog=exog[-3:])\n",
    "            print('antes do predict')\n",
    "            forecast_values = forecast.predicted_mean\n",
    "            print('depois do predict')\n",
    "            # Adicionar a previsão ao DataFrame\n",
    "            df_forecasts_arimax = pd.concat([df_forecasts_arimax, pd.DataFrame([{\n",
    "                'store_id': store_id,\n",
    "                'product_id': product_id,\n",
    "                'forecast_week_1': forecast_values.iloc[0],\n",
    "                'forecast_week_2': forecast_values.iloc[1],\n",
    "                'forecast_week_3': forecast_values.iloc[2],\n",
    "                'ARIMAX': best_order\n",
    "            }])], ignore_index=True)\n",
    "            \n",
    "            # Calcular métricas (assumindo que você tenha vendas futuras reais para comparação)\n",
    "            # Substituir 'actual_future_sales' pelos seus dados reais de vendas para as próximas 3 semanas\n",
    "            actual_future_sales = group['sales'][-3:]  # Ajustar com base na disponibilidade dos dados reais\n",
    "            if len(actual_future_sales) == 3:\n",
    "                mse, rmse, mae, mape = calculate_metrics(actual_future_sales, forecast_values)\n",
    "                # Adicionar as métricas ao DataFrame\n",
    "                df_metrics_arimax = pd.concat([df_metrics_arimax, pd.DataFrame([{\n",
    "                    'store_id': store_id,\n",
    "                    'product_id': product_id,\n",
    "                    'mse': mse,\n",
    "                    'rmse': rmse,\n",
    "                    'mae': mae,\n",
    "                    'mape': mape\n",
    "                }])], ignore_index=True)\n",
    "            else:\n",
    "                df_product_error_arimax = pd.concat([df_product_error_arimax, pd.DataFrame([{\n",
    "                    'store_id': store_id,\n",
    "                    'product_id': product_id,\n",
    "                    'error_message': 'Not enough actual future data to calculate metrics'\n",
    "                }])], ignore_index=True)\n",
    "        else:\n",
    "            df_product_error_arimax = pd.concat([df_product_error_arimax, pd.DataFrame([{\n",
    "                'store_id': store_id,\n",
    "                'product_id': product_id,\n",
    "                'error_message': 'Failed to find suitable ARIMAX model'\n",
    "            }])], ignore_index=True)\n",
    "    except ValueError as ve:\n",
    "        logging.error(f\"ValueError fitting ARIMAX for Store: {store_id}, Product: {product_id}\")\n",
    "        logging.error(str(ve))\n",
    "        df_product_error_arimax = pd.concat([df_product_error_arimax, pd.DataFrame([{\n",
    "            'store_id': store_id,\n",
    "            'product_id': product_id,\n",
    "            'error_message': str(ve)\n",
    "        }])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fitting ARIMAX for Store: {store_id}, Product: {product_id}\")\n",
    "        logging.error(str(e))\n",
    "        df_product_error_arimax = pd.concat([df_product_error_arimax, pd.DataFrame([{\n",
    "            'store_id': store_id,\n",
    "            'product_id': product_id,\n",
    "            'error_message': str(e)\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "# Salvar os DataFrames em arquivos CSV (ou qualquer outro formato desejado)\n",
    "df_forecasts_arimax.to_csv('forecasts_arimax.csv', index=False)\n",
    "df_product_error_arimax.to_csv('product_errors_arimax.csv', index=False)\n",
    "df_metrics_arimax.to_csv('metrics_results_arimax.csv', index=False)\n",
    "\n",
    "# Exibir as primeiras linhas dos DataFrames de resultados\n",
    "print(\"Previsões ARIMAX:\")\n",
    "print(df_forecasts_arimax.head())\n",
    "\n",
    "print(\"\\nErros de Produtos ARIMAX:\")\n",
    "print(df_product_error_arimax.head())\n",
    "\n",
    "print(\"\\nMétricas ARIMAX:\")\n",
    "print(df_metrics_arimax.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [store_id, product_id, mse, rmse, mae, mape]\n",
       "Index: []"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_arimax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
