{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages gerais\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "\n",
    "# df_sales_ dataset\n",
    "df_sales_filtered_all = joblib.load('df_sales_filtered_all.pkl')\n",
    "df_sales_filtered_2018_2019 = joblib.load('df_sales_filtered_2018_2019.pkl')\n",
    "df_sales_filtered_2019 = joblib.load('df_sales_filtered_2019.pkl')\n",
    "df_sales_filtered_last_6_month = joblib.load('df_sales_filtered_last_6_month.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Create a date field based in Year and Week of the year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 But the date to make sense should be the last day in that specific week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# Function to get the last day of the week using ISO calendar\n",
    "def get_last_day_of_iso_week(year, week):\n",
    "    first_day_of_year = datetime.datetime(year, 1, 4)  # 4th January is always in the first ISO week\n",
    "    first_monday_of_year = first_day_of_year - datetime.timedelta(days=first_day_of_year.weekday())\n",
    "    week_start_date = first_monday_of_year + datetime.timedelta(weeks=week-1)\n",
    "    return week_start_date + datetime.timedelta(days=6)\n",
    "\n",
    "# Applying function to DataFrame\n",
    "df_sales_filtered_last_6_month['last_day_of_week'] = df_sales_filtered_last_6_month.apply(\n",
    "    lambda x: get_last_day_of_iso_week(x['year'], x['week']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_filtered_last_6_month[(df_sales_filtered_last_6_month['store_id'] == 'S0097') & (df_sales_filtered_last_6_month['product_id'] == 'P0704')].tail(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Convert date to time series by set as index and sort that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'date' column as index and sort by date\n",
    "df_sales_filtered_last_6_month.set_index('last_day_of_week', inplace=True)\n",
    "df_sales_filtered_last_6_month.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_filtered_last_6_month.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Prepare to apply ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'store_id' and 'product_id'\n",
    "grouped = df_sales_filtered_last_6_month.groupby(['store_id', 'product_id'])\n",
    "\n",
    "# Create a DataFrame to store forecasts and a data frame to have those product/store with error\n",
    "df_forecasts = pd.DataFrame(columns=['store_id', 'product_id', 'forecast_week_1', 'forecast_week_2', 'forecast_week_3'])\n",
    "df_product_error = pd.DataFrame(columns=['store_id', 'product_id', 'error_message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "\n",
    "# Iterate over each group\n",
    "for (store_id, product_id), group in grouped:\n",
    "    # Reindex to ensure complete weekly intervals\n",
    "    group = group.asfreq('W-SUN', method='pad')\n",
    "    \n",
    "    # Ensure there are enough data points to fit the model\n",
    "    if len(group) < 2:\n",
    "        df_product_error = pd.concat([df_product_error, pd.DataFrame([{\n",
    "            'store_id': store_id,\n",
    "            'product_id': product_id,\n",
    "            'error_message': 'Not enough data points to fit ARIMA model'\n",
    "        }])], ignore_index=True)\n",
    "        continue\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")  # specify to ignore warning messages\n",
    "\n",
    "    # Fit ARIMA model\n",
    "    try:\n",
    "        model = ARIMA(group['sales'], order=(1, 1, 1))\n",
    "        model_fit = model.fit()\n",
    "        \n",
    "        # Forecast future sales (next 3 weeks)\n",
    "        forecast = model_fit.forecast(steps=3)\n",
    "        \n",
    "        # Append the forecast to the DataFrame\n",
    "        df_forecasts = pd.concat([df_forecasts, pd.DataFrame([{\n",
    "            'store_id': store_id,\n",
    "            'product_id': product_id,\n",
    "            'forecast_week_1': forecast[0],\n",
    "            'forecast_week_2': forecast[1],\n",
    "            'forecast_week_3': forecast[2]\n",
    "        }])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting ARIMA for Store: {store_id}, Product: {product_id}\")\n",
    "        print(str(e))\n",
    "        df_product_error = pd.concat([df_product_error, pd.DataFrame([{\n",
    "            'store_id': store_id,\n",
    "            'product_id': product_id,\n",
    "            'error_message': str(e)\n",
    "        }])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "# Carregar o DataFrame\n",
    "df_sales_filtered_last_6_month = joblib.load('df_sales_filtered_last_6_month.pkl')\n",
    "\n",
    "# DataFrames para armazenar resultados\n",
    "df_forecasts = pd.DataFrame()\n",
    "df_product_error = pd.DataFrame()\n",
    "\n",
    "# Agrupar os dados por store_id e product_id\n",
    "grouped = df_sales_filtered_last_6_month.groupby(['store_id', 'product_id'])\n",
    "\n",
    "# Função para converter ano e semana em uma data\n",
    "def year_week_to_date(year, week):\n",
    "    return pd.to_datetime(f'{year}-W{week}-1', format='%Y-W%U-%w')\n",
    "\n",
    "# Iteração sobre cada grupo\n",
    "for (store_id, product_id), group in grouped:\n",
    "    # Definir a coluna 'date' como índice e reindexar para garantir intervalos semanais completos\n",
    "    group['date'] = group.apply(lambda row: year_week_to_date(row['year'], row['week']), axis=1)\n",
    "    group = group.set_index('date').asfreq('W-SUN', method='pad')\n",
    "\n",
    "    # Verifica se há dados suficientes\n",
    "    if len(group) < 2:\n",
    "        df_product_error = pd.concat([df_product_error, pd.DataFrame([{\n",
    "            'store_id': store_id,\n",
    "            'product_id': product_id,\n",
    "            'error_message': 'Not enough data points to fit ARIMA model'\n",
    "        }])], ignore_index=True)\n",
    "        continue\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")  # Ignorar avisos\n",
    "\n",
    "    try:\n",
    "        # Ajustar modelo ARIMA\n",
    "        model_arima = ARIMA(group['sales'], order=(1, 1, 1))\n",
    "        model_fit_arima = model_arima.fit()\n",
    "        forecast_arima = model_fit_arima.forecast(steps=3)\n",
    "\n",
    "        # Ajustar modelo SARIMA\n",
    "        model_sarima = SARIMAX(group['sales'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "        model_fit_sarima = model_sarima.fit()\n",
    "        forecast_sarima = model_fit_sarima.forecast(steps=3)\n",
    "\n",
    "        # Ajustar modelo ARIMAX\n",
    "        exog_vars = group[['revenue', 'stock', 'price']]  # Supondo que essas são as variáveis exógenas\n",
    "        model_arimax = SARIMAX(group['sales'], order=(1, 1, 1), exog=exog_vars)\n",
    "        model_fit_arimax = model_arimax.fit()\n",
    "        forecast_arimax = model_fit_arimax.forecast(steps=3, exog=exog_vars[-3:])\n",
    "\n",
    "        # Usar pmdarima para encontrar o melhor modelo ARIMA automaticamente\n",
    "        auto_model = auto_arima(group['sales'], seasonal=False, trace=True)\n",
    "        auto_forecast = auto_model.predict(n_periods=3)\n",
    "\n",
    "        # Comparação dos modelos\n",
    "        mse_arima = mean_squared_error(group['sales'][-3:], forecast_arima)\n",
    "        mse_sarima = mean_squared_error(group['sales'][-3:], forecast_sarima)\n",
    "        mse_arimax = mean_squared_error(group['sales'][-3:], forecast_arimax)\n",
    "        mse_auto_arima = mean_squared_error(group['sales'][-3:], auto_forecast)\n",
    "\n",
    "        # Imprimir resultados de MSE\n",
    "        print(f'Store: {store_id}, Product: {product_id}')\n",
    "        print(f'MSE ARIMA: {mse_arima}')\n",
    "        print(f'MSE SARIMA: {mse_sarima}')\n",
    "        print(f'MSE ARIMAX: {mse_arimax}')\n",
    "        print(f'MSE Auto ARIMA: {mse_auto_arima}')\n",
    "\n",
    "        # Adicionar previsões ao DataFrame\n",
    "        df_forecasts = pd.concat([df_forecasts, pd.DataFrame([{\n",
    "            'store_id': store_id,\n",
    "            'product_id': product_id,\n",
    "            'forecast_arima_week_1': forecast_arima[0],\n",
    "            'forecast_arima_week_2': forecast_arima[1],\n",
    "            'forecast_arima_week_3': forecast_arima[2],\n",
    "            'forecast_sarima_week_1': forecast_sarima[0],\n",
    "            'forecast_sarima_week_2': forecast_sarima[1],\n",
    "            'forecast_sarima_week_3': forecast_sarima[2],\n",
    "            'forecast_arimax_week_1': forecast_arimax[0],\n",
    "            'forecast_arimax_week_2': forecast_arimax[1],\n",
    "            'forecast_arimax_week_3': forecast_arimax[2],\n",
    "            'forecast_auto_arima_week_1': auto_forecast[0],\n",
    "            'forecast_auto_arima_week_2': auto_forecast[1],\n",
    "            'forecast_auto_arima_week_3': auto_forecast[2]\n",
    "        }])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting models for Store: {store_id}, Product: {product_id}\")\n",
    "        print(str(e))\n",
    "        df_product_error = pd.concat([df_product_error, pd.DataFrame([{\n",
    "            'store_id': store_id,\n",
    "            'product_id': product_id,\n",
    "            'error_message': str(e)\n",
    "        }])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
